{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Asad Shah\\anaconda3\\envs\\AI2_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Asad Shah\\anaconda3\\envs\\AI2_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Asad Shah\\anaconda3\\envs\\AI2_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Asad Shah\\anaconda3\\envs\\AI2_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Asad Shah\\anaconda3\\envs\\AI2_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Asad Shah\\anaconda3\\envs\\AI2_course\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/Asad Shah/Documents/final/final/fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asad Shah\\anaconda3\\envs\\AI2_course\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Asad Shah\\anaconda3\\envs\\AI2_course\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Asad Shah\\anaconda3\\envs\\AI2_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/65\n",
      "28709/28709 [==============================] - 474s 17ms/step - loss: 1.7455 - acc: 0.2843 - val_loss: 1.6138 - val_acc: 0.3625\n",
      "Epoch 2/65\n",
      "28709/28709 [==============================] - 421s 15ms/step - loss: 1.5276 - acc: 0.4006 - val_loss: 1.4160 - val_acc: 0.4564\n",
      "Epoch 3/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 1.4099 - acc: 0.4515 - val_loss: 1.3140 - val_acc: 0.4904\n",
      "Epoch 4/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 1.3458 - acc: 0.4805 - val_loss: 1.2807 - val_acc: 0.5043\n",
      "Epoch 5/65\n",
      "28709/28709 [==============================] - 410s 14ms/step - loss: 1.3006 - acc: 0.4959 - val_loss: 1.2400 - val_acc: 0.5127\n",
      "Epoch 6/65\n",
      "28709/28709 [==============================] - 407s 14ms/step - loss: 1.2660 - acc: 0.5155 - val_loss: 1.2182 - val_acc: 0.5322\n",
      "Epoch 7/65\n",
      "28709/28709 [==============================] - 411s 14ms/step - loss: 1.2324 - acc: 0.5258 - val_loss: 1.1942 - val_acc: 0.5411\n",
      "Epoch 8/65\n",
      "28709/28709 [==============================] - 407s 14ms/step - loss: 1.2102 - acc: 0.5335 - val_loss: 1.1971 - val_acc: 0.5322\n",
      "Epoch 9/65\n",
      "28709/28709 [==============================] - 409s 14ms/step - loss: 1.1851 - acc: 0.5435 - val_loss: 1.1957 - val_acc: 0.5450\n",
      "Epoch 10/65\n",
      "28709/28709 [==============================] - 409s 14ms/step - loss: 1.1677 - acc: 0.5529 - val_loss: 1.1733 - val_acc: 0.5520\n",
      "Epoch 11/65\n",
      "28709/28709 [==============================] - 406s 14ms/step - loss: 1.1443 - acc: 0.5613 - val_loss: 1.1721 - val_acc: 0.5600\n",
      "Epoch 12/65\n",
      "28709/28709 [==============================] - 412s 14ms/step - loss: 1.1278 - acc: 0.5703 - val_loss: 1.1763 - val_acc: 0.5511\n",
      "Epoch 13/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 1.1101 - acc: 0.5743 - val_loss: 1.1578 - val_acc: 0.5589\n",
      "Epoch 14/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 1.0933 - acc: 0.5824 - val_loss: 1.1462 - val_acc: 0.5695\n",
      "Epoch 15/65\n",
      "28709/28709 [==============================] - 409s 14ms/step - loss: 1.0785 - acc: 0.5865 - val_loss: 1.1418 - val_acc: 0.5626\n",
      "Epoch 16/65\n",
      "28709/28709 [==============================] - 407s 14ms/step - loss: 1.0619 - acc: 0.5954 - val_loss: 1.1693 - val_acc: 0.5659\n",
      "Epoch 17/65\n",
      "28709/28709 [==============================] - 412s 14ms/step - loss: 1.0530 - acc: 0.5974 - val_loss: 1.1566 - val_acc: 0.5684\n",
      "Epoch 18/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 1.0335 - acc: 0.6076 - val_loss: 1.1650 - val_acc: 0.5698\n",
      "Epoch 19/65\n",
      "28709/28709 [==============================] - 412s 14ms/step - loss: 1.0197 - acc: 0.6141 - val_loss: 1.1631 - val_acc: 0.5662\n",
      "Epoch 20/65\n",
      "28709/28709 [==============================] - 409s 14ms/step - loss: 1.0061 - acc: 0.6207 - val_loss: 1.1483 - val_acc: 0.5734\n",
      "Epoch 21/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 0.9898 - acc: 0.6186 - val_loss: 1.1425 - val_acc: 0.5723\n",
      "Epoch 22/65\n",
      "28709/28709 [==============================] - 411s 14ms/step - loss: 0.9795 - acc: 0.6278 - val_loss: 1.1539 - val_acc: 0.5751\n",
      "Epoch 23/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 0.9684 - acc: 0.6307 - val_loss: 1.1436 - val_acc: 0.5706\n",
      "Epoch 24/65\n",
      "28709/28709 [==============================] - 412s 14ms/step - loss: 0.9552 - acc: 0.6375 - val_loss: 1.1403 - val_acc: 0.5793\n",
      "Epoch 25/65\n",
      "28709/28709 [==============================] - 410s 14ms/step - loss: 0.9435 - acc: 0.6413 - val_loss: 1.1647 - val_acc: 0.5715\n",
      "Epoch 26/65\n",
      "28709/28709 [==============================] - 411s 14ms/step - loss: 0.9282 - acc: 0.6459 - val_loss: 1.1815 - val_acc: 0.5759\n",
      "Epoch 27/65\n",
      "28709/28709 [==============================] - 409s 14ms/step - loss: 0.9157 - acc: 0.6511 - val_loss: 1.1759 - val_acc: 0.5765\n",
      "Epoch 28/65\n",
      "28709/28709 [==============================] - 406s 14ms/step - loss: 0.9065 - acc: 0.6574 - val_loss: 1.1660 - val_acc: 0.5790\n",
      "Epoch 29/65\n",
      "28709/28709 [==============================] - 412s 14ms/step - loss: 0.8897 - acc: 0.6606 - val_loss: 1.1889 - val_acc: 0.5729\n",
      "Epoch 30/65\n",
      "28709/28709 [==============================] - 409s 14ms/step - loss: 0.8865 - acc: 0.6641 - val_loss: 1.1906 - val_acc: 0.5751\n",
      "Epoch 31/65\n",
      "28709/28709 [==============================] - 410s 14ms/step - loss: 0.8670 - acc: 0.6663 - val_loss: 1.2233 - val_acc: 0.5667\n",
      "Epoch 32/65\n",
      "28709/28709 [==============================] - 409s 14ms/step - loss: 0.8695 - acc: 0.6728 - val_loss: 1.1742 - val_acc: 0.5790\n",
      "Epoch 33/65\n",
      "28709/28709 [==============================] - 407s 14ms/step - loss: 0.8538 - acc: 0.6751 - val_loss: 1.2084 - val_acc: 0.5709\n",
      "Epoch 34/65\n",
      "28709/28709 [==============================] - 411s 14ms/step - loss: 0.8375 - acc: 0.6820 - val_loss: 1.2139 - val_acc: 0.5821\n",
      "Epoch 35/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 0.8272 - acc: 0.6865 - val_loss: 1.1789 - val_acc: 0.5779\n",
      "Epoch 36/65\n",
      "28709/28709 [==============================] - 413s 14ms/step - loss: 0.8134 - acc: 0.6922 - val_loss: 1.2009 - val_acc: 0.5804\n",
      "Epoch 37/65\n",
      "28709/28709 [==============================] - 413s 14ms/step - loss: 0.8009 - acc: 0.6970 - val_loss: 1.2434 - val_acc: 0.5851\n",
      "Epoch 38/65\n",
      "28709/28709 [==============================] - 409s 14ms/step - loss: 0.7911 - acc: 0.7019 - val_loss: 1.2251 - val_acc: 0.5843\n",
      "Epoch 39/65\n",
      "28709/28709 [==============================] - 411s 14ms/step - loss: 0.7896 - acc: 0.7028 - val_loss: 1.2533 - val_acc: 0.5701\n",
      "Epoch 40/65\n",
      "28709/28709 [==============================] - 409s 14ms/step - loss: 0.7804 - acc: 0.7072 - val_loss: 1.2489 - val_acc: 0.5795\n",
      "Epoch 41/65\n",
      "28709/28709 [==============================] - 413s 14ms/step - loss: 0.7666 - acc: 0.7093 - val_loss: 1.2703 - val_acc: 0.5770\n",
      "Epoch 42/65\n",
      "28709/28709 [==============================] - 409s 14ms/step - loss: 0.7506 - acc: 0.7179 - val_loss: 1.2710 - val_acc: 0.5779\n",
      "Epoch 43/65\n",
      "28709/28709 [==============================] - 414s 14ms/step - loss: 0.7388 - acc: 0.7231 - val_loss: 1.2853 - val_acc: 0.5773\n",
      "Epoch 44/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 0.7282 - acc: 0.7299 - val_loss: 1.3180 - val_acc: 0.5690\n",
      "Epoch 45/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 0.7286 - acc: 0.7268 - val_loss: 1.2942 - val_acc: 0.5815\n",
      "Epoch 46/65\n",
      "28709/28709 [==============================] - 412s 14ms/step - loss: 0.7168 - acc: 0.7333 - val_loss: 1.2609 - val_acc: 0.5695\n",
      "Epoch 47/65\n",
      "28709/28709 [==============================] - 410s 14ms/step - loss: 0.7092 - acc: 0.7343 - val_loss: 1.2810 - val_acc: 0.5748\n",
      "Epoch 48/65\n",
      "28709/28709 [==============================] - 412s 14ms/step - loss: 0.7042 - acc: 0.7357 - val_loss: 1.3068 - val_acc: 0.5793\n",
      "Epoch 49/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 0.6917 - acc: 0.7413 - val_loss: 1.3338 - val_acc: 0.5717\n",
      "Epoch 50/65\n",
      "28709/28709 [==============================] - 411s 14ms/step - loss: 0.6933 - acc: 0.7409 - val_loss: 1.2964 - val_acc: 0.5720\n",
      "Epoch 51/65\n",
      "28709/28709 [==============================] - 411s 14ms/step - loss: 0.6980 - acc: 0.7397 - val_loss: 1.3657 - val_acc: 0.5687\n",
      "Epoch 52/65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 408s 14ms/step - loss: 0.6718 - acc: 0.7499 - val_loss: 1.3053 - val_acc: 0.5715\n",
      "Epoch 53/65\n",
      "28709/28709 [==============================] - 411s 14ms/step - loss: 0.6620 - acc: 0.7556 - val_loss: 1.3868 - val_acc: 0.5712\n",
      "Epoch 54/65\n",
      "28709/28709 [==============================] - 407s 14ms/step - loss: 0.6598 - acc: 0.7517 - val_loss: 1.3586 - val_acc: 0.5717\n",
      "Epoch 55/65\n",
      "28709/28709 [==============================] - 412s 14ms/step - loss: 0.6553 - acc: 0.7562 - val_loss: 1.3523 - val_acc: 0.5734\n",
      "Epoch 56/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 0.6398 - acc: 0.7623 - val_loss: 1.4229 - val_acc: 0.5695\n",
      "Epoch 57/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 0.6365 - acc: 0.7660 - val_loss: 1.3762 - val_acc: 0.5804\n",
      "Epoch 58/65\n",
      "28709/28709 [==============================] - 410s 14ms/step - loss: 0.6284 - acc: 0.7701 - val_loss: 1.3762 - val_acc: 0.5784\n",
      "Epoch 59/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 0.6201 - acc: 0.7704 - val_loss: 1.3743 - val_acc: 0.5807\n",
      "Epoch 60/65\n",
      "28709/28709 [==============================] - 413s 14ms/step - loss: 0.6135 - acc: 0.7709 - val_loss: 1.3860 - val_acc: 0.5720\n",
      "Epoch 61/65\n",
      "28709/28709 [==============================] - 409s 14ms/step - loss: 0.6226 - acc: 0.7694 - val_loss: 1.4403 - val_acc: 0.5815\n",
      "Epoch 62/65\n",
      "28709/28709 [==============================] - 410s 14ms/step - loss: 0.6048 - acc: 0.7775 - val_loss: 1.4179 - val_acc: 0.5678\n",
      "Epoch 63/65\n",
      "28709/28709 [==============================] - 410s 14ms/step - loss: 0.6101 - acc: 0.7789 - val_loss: 1.4753 - val_acc: 0.5773\n",
      "Epoch 64/65\n",
      "28709/28709 [==============================] - 408s 14ms/step - loss: 0.6018 - acc: 0.7795 - val_loss: 1.3818 - val_acc: 0.5823\n",
      "Epoch 65/65\n",
      "28709/28709 [==============================] - 412s 14ms/step - loss: 0.5966 - acc: 0.7816 - val_loss: 1.3774 - val_acc: 0.5731\n"
     ]
    }
   ],
   "source": [
    "X_train,train_y,X_test,test_y=[],[],[],[]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "           X_train.append(np.array(val,'float32'))\n",
    "           train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "           X_test.append(np.array(val,'float32'))\n",
    "           test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")\n",
    "\n",
    "\n",
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 65\n",
    "width, height = 48, 48\n",
    "\n",
    "\n",
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')\n",
    "\n",
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
    "\n",
    "#cannot produce\n",
    "#normalizing data between oand 1\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
    "\n",
    "# print(f\"shape:{X_train.shape}\")\n",
    "##designing the cnn\n",
    "#1st convolution layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "#Compliling the model\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Training the model\n",
    "model.fit(X_train, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)\n",
    "\n",
    "\n",
    "#Saving the  model to  use it later on\n",
    "fer_json = model.to_json()\n",
    "with open(\"newModel2.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"newModel2.h5\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
